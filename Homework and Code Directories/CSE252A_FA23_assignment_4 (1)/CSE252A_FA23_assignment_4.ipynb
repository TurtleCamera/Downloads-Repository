{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3Jp_VhCl4te",
    "tags": []
   },
   "source": [
    "# CSE 252A Computer Vision I Fall 2023 - Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gISBijp3l4ti",
    "tags": []
   },
   "source": [
    "Instructor: Ben Ochoa\n",
    "\n",
    "Due: Wed, Dec 6, 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:**\n",
    "\n",
    "**PID:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOXXS2dOl4tj",
    "tags": []
   },
   "source": [
    "## Instructions\n",
    "\n",
    "Please answer the questions below using Python in the attached Jupyter notebook and follow the guidelines below:\n",
    " \n",
    "- This assignment must be completed **individually**. For more details, please follow the Academic Integrity Policy and Collaboration Policy on [Canvas](https://canvas.ucsd.edu).\n",
    "\n",
    "- All the solutions must be written in this Jupyter notebook.\n",
    "\n",
    "- You may use basic algebra packages (e.g., `NumPy`, `SciPy`, etc) but you are not allowed to use the packages that directly solve the problems. Feel free to ask the instructor and the teaching assistants if you are unsure about the packages to use.\n",
    "\n",
    "- It is highly recommended that you begin working on this assignment early.\n",
    "\n",
    "- **You must submit 3 files on Gradescope - `.pdf` , `.ipynb` and `.py` file where the .py file is the conversion of your .ipynb to .py file . You must mark each problem on Gradescope in the pdf.** \n",
    "    To convert the notebook to PDF, you can choose one way below:\n",
    "\n",
    "    1. You can print the web page and save as PDF (e.g., Chrome: Right click the web page $\\rightarrow$ Print... $\\rightarrow$ Choose \"Destination: Save as PDF\" and click \"Save\").\n",
    "\n",
    "    2. You can find the export option in the header: File $\\rightarrow$ Download as $\\rightarrow$ \"PDF via LaTeX\"\n",
    "\n",
    "    To convert the notebook (.ipynb) to .py file use the following command:\n",
    "\n",
    "<center> jupyter nbconvert --to script filename.ipynb --output output_filename.py </center>\n",
    "\n",
    "- Please make sure the content in each cell (e.g., code, output images, printed results, etc.) are clearly visible and are not cut-out or partially cropped in your final PDF file.\n",
    "\n",
    "- While submitting on gradescope, please make sure to assign the relevant pages in your PDF submission for each problem.\n",
    "\n",
    "**Late Policy:** Assignments submitted late will receive a 15% grade reduction for each 12 hours late (i.e., 30% per day). Assignments will not be accepted 72 hours after the due date. If you require an extension (for personal reasons only) to a due date, you must request one as far in advance as possible. Extensions requested close to or after the due date will only be granted for clear emergencies or clearly unforeseeable circumstances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5pbyh5yl4tk",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Problem 1: Machine Learning [28 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m16Ecnjdl4tk"
   },
   "source": [
    "In this problem, you will implement several machine learning solutions for computer vision problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQpyhnvIl4tk"
   },
   "source": [
    "### Problem 1.1: Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCC0JD1Il4tl"
   },
   "source": [
    "We will use [Scikit-learn (Sklearn)](https://scikit-learn.org/stable/) module in for this problem. It is the most useful and robust library for machine learning in Python. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python. This library, which is largely written in Python, is built upon NumPy, SciPy and Matplotlib. \n",
    "\n",
    "Get started by installing the Sklearn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZiYlaSol4tm"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SQL5iPKl4to"
   },
   "source": [
    "### Problem 1.2: Download MNIST data [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_f1_Tz7l4tq"
   },
   "source": [
    "The [MNIST database](http://yann.lecun.com/exdb/mnist/) (Modified National Institute of Standards and Technology database) is a well-known dataset consisting of 28x28 grayscale images of handwritten digits. For this problem, we will use Sklearn to do machine learning classification on the MNIST database.\n",
    "\n",
    "Sklearn provides a lower-resolution MNIST database with 8x8 pixel images of digits. The `images` attribute of the dataset stores 8x8 arrays of grayscale values for each image. The `target` attribute of the dataset stores the digit each image represents. Complete `plot_mnist_sample()` to plot a 2x5 figure, where each grid displays a sample image from a category. The following image gives an example:\n",
    "<!-- <img src=\"./fig/eg_mnist.PNG\" alt=\"drawing\" width=\"400\"/> -->\n",
    "![mnist](fig/eg_mnist.PNG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbXpRqO1l4tq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PTXSZhWl4tr"
   },
   "outputs": [],
   "source": [
    "# Download MNIST Dataset from Sklearn\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Print to show there are 1797 images (8 by 8 images for a dimensionality of 64)\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "\n",
    "# Print to show there are 1797 labels (integers from 0-9)\n",
    "print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p43geFB4l4tr"
   },
   "outputs": [],
   "source": [
    "def plot_mnist_sample(digits):\n",
    "    \"\"\"\n",
    "    This function plots a sample image for each category,\n",
    "    The result is a figure with 2x5 grid of images.\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEj8kOdul4tr"
   },
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT CHANGE\n",
    "# This code is for you to plot the results.\n",
    "\n",
    "plot_mnist_sample(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD68VE3pl4ts"
   },
   "source": [
    "### Problem 1.3: Recognizing hand-written digits with Sklearn [5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ctL_Gwl4ts"
   },
   "source": [
    "One of the most amazing things about the Sklearn library is that it provides an easy way to build and call different models. In this part, we will get experience with  `LogisticRegressionClassifier` and `kNNClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDZ8BK3Ol4ts"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "#### Some helper functions are given below####\n",
    "def DataBatch(data, label, batchsize, shuffle=True):\n",
    "    \"\"\"\n",
    "    This function provides a generator for batches of data that \n",
    "    yields data (batchsize, 3, 32, 32) and labels (batchsize)\n",
    "    if shuffle, it will load batches in a random order\n",
    "    \"\"\"\n",
    "    n = data.shape[0]\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(n)\n",
    "    else:\n",
    "        index = np.arange(n)\n",
    "    for i in range(int(np.ceil(n/batchsize))):\n",
    "        inds = index[i*batchsize : min(n,(i+1)*batchsize)]\n",
    "        yield data[inds], label[inds]\n",
    "\n",
    "def test(testData, testLabels, classifier):\n",
    "    \"\"\"\n",
    "    Call this function to test the accuracy of a classifier\n",
    "    \"\"\"\n",
    "    batchsize=50\n",
    "    correct=0.\n",
    "    for data,label in DataBatch(testData,testLabels,batchsize,shuffle=False):\n",
    "        prediction = classifier(data)\n",
    "        correct += np.sum(prediction==label)\n",
    "    return correct/testData.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQ0N2RCZl4tt"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "# Split data into 90% train and 10% test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.images.reshape((len(digits.images), -1)), digits.target, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6JnXh3jl4tt"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class RandomClassifier():\n",
    "    \"\"\"\n",
    "    This is a sample classifier. \n",
    "    given an input it outputs a random class\n",
    "    \"\"\"\n",
    "    def __init__(self, classes=10):\n",
    "        self.classes=classes\n",
    "    def __call__(self, x):\n",
    "        return np.random.randint(self.classes, size=x.shape[0])\n",
    "    \n",
    "class LogisticRegressionClassifier():\n",
    "    def __init__(self, sol='liblinear'):\n",
    "        \"\"\"\n",
    "        Initialize Logistic Regression model.\n",
    "        \n",
    "        Inputs:\n",
    "        sol: Solver method that the Logistic Regression model would use for optimization\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        \"\"\"\n",
    "        Train your model with image data and corresponding labels.\n",
    "        \n",
    "        Inputs:\n",
    "        trainData: Training images (N,64)\n",
    "        trainLabels: Labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Predict the trained model on test data.\n",
    "\n",
    "        Inputs:\n",
    "        x: Test images (N,64)\n",
    "\n",
    "        Returns:\n",
    "        predicted labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "    \n",
    "class kNNClassifier():\n",
    "    def __init__(self, k=3, algorithm='brute'):\n",
    "        \"\"\"\n",
    "        Initialize KNN model.\n",
    "        \n",
    "        Inputs:\n",
    "        k: number of neighbors involved in voting\n",
    "        algorithm: Algorithm used to compute nearest neighbors\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        \"\"\"\n",
    "        Train your model with image data and corresponding labels.\n",
    "        \n",
    "        Inputs:\n",
    "        trainData: Training images (N,64)\n",
    "        trainLabels: Labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "            \n",
    "       \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Predict the trained model on test data.\n",
    "\n",
    "        Inputs:\n",
    "        x: Test images (N,64)\n",
    "\n",
    "        Returns:\n",
    "        predicted labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQ9k9kw-l4tt"
   },
   "outputs": [],
   "source": [
    "# TEST CODE: DO NOT CHANGE\n",
    "randomClassifierX = RandomClassifier()\n",
    "print ('Random classifier accuracy: %f'%test(X_test, y_test, randomClassifierX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOGbN8GDl4tu"
   },
   "outputs": [],
   "source": [
    "# TEST CODE: DO NOT CHANGE\n",
    "# TEST LogisticRegressionClassifier\n",
    "\n",
    "lrClassifierX = LogisticRegressionClassifier()\n",
    "lrClassifierX.train(X_train, y_train)\n",
    "print ('Logistic Regression Classifier classifier accuracy: %f'%test(X_test, y_test, lrClassifierX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WN3IyTafl4tu"
   },
   "outputs": [],
   "source": [
    "# TEST kNNClassifier\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt39SvrEl4tv"
   },
   "source": [
    "### Problem 1.4: Confusion Matrix [5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jm0Zmzcl4tv"
   },
   "source": [
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. Here you will implement a function that computes the confusion matrix for a classifier. The matrix (M) must be $n \\times n$ where $n$ is the number of classes. Entry `M[i,j]` must contain the fraction of images of class `i` that was classified as class `j`. The following example shows the confusion matrix for the `RandomClassifier`. Your task is to plot the results for `LogisticRegressionClassifier` and `kNNClassifier`.\n",
    "<!-- <img src=\"./fig/eg_confusion.PNG\" alt=\"drawing\" width=\"250\"/> -->\n",
    "![confusion](fig/eg_confusion.PNG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HP43z3lOl4tv"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def Confusion(testData, testLabels, classifier):\n",
    "    batchsize=50\n",
    "    correct=0\n",
    "    M=np.zeros((10,10))\n",
    "    num=testData.shape[0]/batchsize\n",
    "    count=0\n",
    "    acc=0\n",
    "    \n",
    "    for data,label in tqdm(DataBatch(testData,testLabels,batchsize,shuffle=False),total=len(testData)//batchsize):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "      \n",
    "    \n",
    "    \n",
    "    return M,acc*100.0/len(testData)\n",
    "\n",
    "def VisualizeConfussion(M):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.imshow(M)\n",
    "    plt.show()\n",
    "    print(np.round(M,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suvefA82l4tv"
   },
   "outputs": [],
   "source": [
    "# TEST/PLOT CODE: DO NOT CHANGE\n",
    "# TEST LogisticRegressionClassifier\n",
    "\n",
    "M,acc = Confusion(X_test, y_test, lrClassifierX)\n",
    "VisualizeConfussion(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWZFcKjal4tw"
   },
   "outputs": [],
   "source": [
    "# TEST/PLOT CODE: DO NOT CHANGE\n",
    "# TEST kNNClassifier\n",
    "\n",
    "M,acc = Confusion(X_test, y_test, knnClassifierX)\n",
    "VisualizeConfussion(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HnFGSRFl4tw"
   },
   "source": [
    "### Problem 1.5: K-Nearest Neighbors (KNN) [7 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l8Vxkoil4tw"
   },
   "source": [
    "For this problem, you will complete a simple kNN classifer without Sklearn. The distance metric is Euclidean distance (L2 norm) in pixel space. You may use the `np.linalg.norm` function to compute distance. $k$ refers to the number of neighbors involved in voting on the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-D-znLZl4tx"
   },
   "outputs": [],
   "source": [
    "class kNNClassifierManual():\n",
    "    def __init__(self, k=3):\n",
    "        self.k=k\n",
    "\n",
    "    def train(self, trainData, trainLabels):\n",
    "        self.X_train = trainData\n",
    "        self.y_train = trainLabels\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for the input data using KNN method.\n",
    "\n",
    "        Inputs:\n",
    "        X: Test images (N,64)\n",
    "\n",
    "        Returns:\n",
    "        predicted labels (N,)\n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPVvwhp0l4tx"
   },
   "outputs": [],
   "source": [
    "# TEST/PLOT CODE: DO NOT CHANGE\n",
    "# TEST kNNClassifierManual\n",
    "\n",
    "knnClassifierManualX = kNNClassifierManual()\n",
    "knnClassifierManualX.train(X_train, y_train)\n",
    "print ('KNN classifier accuracy: %f'%test(X_test, y_test, knnClassifierManualX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZQQIiKPnRQF"
   },
   "source": [
    "### Problem 1.6: Principal Component Analysis (PCA) K-Nearest Neighbors (KNN) [8 pts]\n",
    "Here you will implement a simple KNN classifer in PCA space (for k=3 and 25 principal components).\n",
    "You must implement PCA yourself using SVD (you may not use sklearn.decomposition.PCA\n",
    "or any other package that directly implements PCA transformations)\n",
    "\n",
    "You may use your previous implementation of the KNN classifier in this part.\n",
    "\n",
    "#### Compare runtimes\n",
    "Is the testing time for PCA KNN classifier more or less than that for KNN classifier? Comment on why it differs if it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e06z90dxm7Af"
   },
   "outputs": [],
   "source": [
    "class PCAKNNClassifer():\n",
    "    def __init__(self, components=25, k=3):\n",
    "        \"\"\"\n",
    "        Initialize PCA kNN classifier\n",
    "\n",
    "        Inputs:\n",
    "        components: number of principal components\n",
    "        k: number of neighbors involved in voting\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        \"\"\"\n",
    "        Train your model with image data and corresponding labels.\n",
    "        \n",
    "        Inputs:\n",
    "        trainData: Training images (N,64)\n",
    "        trainLabels: Labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Predict the trained model on test data.\n",
    "\n",
    "        Inputs:\n",
    "        x: Test images (N,64)\n",
    "\n",
    "        Returns:\n",
    "        predicted labels (N,)\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "\n",
    "# test your classifier with only the first 100 training examples (use this\n",
    "# while debugging)\n",
    "pcaknnClassiferX = PCAKNNClassifer()\n",
    "pcaknnClassiferX.train(X_train[:100], y_train[:100])\n",
    "print ('PCA KNN classifier accuracy: %f'%test(X_test, y_test, pcaknnClassiferX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSbD_cdeoOY5"
   },
   "outputs": [],
   "source": [
    "# test your classifier with all the training examples\n",
    "pcaknnClassifer = PCAKNNClassifer()\n",
    "pcaknnClassifer.train(X_train, y_train)\n",
    "# display confusion matrix for your PCA KNN classifier with all the training examples\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "\n",
    "\n",
    "print ('PCA KNN classifier accuracy: %f'%acc_pca)\n",
    "VisualizeConfussion(M_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuQfPRnEpM9c"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8ol8VCDpV8Q"
   },
   "source": [
    "## Problem 2: Deep learning [28 pts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYf3GsdmpfvS"
   },
   "source": [
    "### Problem 2.1 Initial setup [1 pts]\n",
    "\n",
    "Follow the directions on https://pytorch.org/get-started/locally/ to install Pytorch on your computer. \n",
    "\n",
    "Note: You will not need GPU support for this assignment so don't worry if you don't have one. Furthermore, installing with GPU support is often more difficult to configure so it is suggested that you install the CPU only version. TA's will not provide any support related to GPU or CUDA.\n",
    "\n",
    "Run the torch import statements below to verify your instalation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQC44M9Rp1VR"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ai7Lktn5tLBz"
   },
   "source": [
    "In this problem, we will use the full dataset of MNIST database with 28x28 pixel images of digits.\n",
    "\n",
    "Download the MNIST data from http://yann.lecun.com/exdb/mnist/.\n",
    "\n",
    "Download the 4 zipped files, extract them into one folder, and change the variable 'path' in the code below. (Code taken from https://gist.github.com/akesling/5358964 )\n",
    "\n",
    "Plot one random example image corresponding to each label from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6owsEdLttV9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "# Change path as required\n",
    "path = \"./mnist/\"\n",
    "\n",
    "def read(dataset = \"training\", datatype='images'):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "    \n",
    "    if(datatype=='images'):\n",
    "        get_data = lambda idx: img[idx]\n",
    "    elif(datatype=='labels'):\n",
    "        get_data = lambda idx: lbl[idx]\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_data(i)\n",
    "        \n",
    "X_train=np.array(list(read('training','images')))\n",
    "y_train=np.array(list(read('training','labels')))\n",
    "X_test=np.array(list(read('testing','images')))\n",
    "y_test=np.array(list(read('testing','labels')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5tK3MeXN5v2"
   },
   "outputs": [],
   "source": [
    "def plot_mnist_sample_high_res(X_train, y_train):\n",
    "    \"\"\"\n",
    "    This function plots a sample image for each category,\n",
    "    The result is a figure with 2x5 grid of images.\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNCBDoFnN8B5"
   },
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT CHANGE\n",
    "# This code is for you to plot the results.\n",
    "\n",
    "plot_mnist_sample_high_res(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wu-weDbqEAY"
   },
   "source": [
    "### Problem 2.2:  Training with PyTorch [8 pts]\n",
    "Below is some helper code to train your deep networks. \n",
    "Complete the train function for DNN below. \n",
    "\n",
    "You must write down the training operations in this function. That means, for a batch of data you have to initialize the gradients, forward propagate the data, compute error, do back propagation and finally update the parameters. You would have to choose an appropriate loss function and optimizer from PyTorch for this problem.\n",
    "\n",
    "This function will be used in the following questions with different networks.\n",
    "You can look at https://pytorch.org/tutorials/beginner/pytorch_with_examples.html for reference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky0FksEwqDta"
   },
   "outputs": [],
   "source": [
    "# base class for your deep neural networks. It implements the training loop (train_net).\n",
    "\n",
    "\n",
    "import torch.nn.init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def train_net(self, X_train, y_train, epochs=1, batchSize=50):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        inputs = Variable(torch.FloatTensor(x))\n",
    "        prediction = self.forward(inputs)\n",
    "        return np.argmax(prediction.data.cpu().numpy(), 1)\n",
    "\n",
    "# helper function to get weight variable\n",
    "def weight_variable(shape):\n",
    "    initial = torch.Tensor(truncnorm.rvs(-1/0.01, 1/0.01, scale=0.01, size=shape))\n",
    "    return Parameter(initial, requires_grad=True)\n",
    "\n",
    "# helper function to get bias variable\n",
    "def bias_variable(shape):\n",
    "    initial = torch.Tensor(np.ones(shape)*0.1)\n",
    "    return Parameter(initial, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HYVuzbtosJo"
   },
   "outputs": [],
   "source": [
    "# example linear classifier - input connected to output\n",
    "# you can take this as an example to learn how to extend DNN class\n",
    "class LinearClassifier(DNN):\n",
    "    def __init__(self, in_features=28*28, classes=10):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        # in_features=28*28\n",
    "        self.weight1 = weight_variable((classes, in_features))\n",
    "        self.bias1 = bias_variable((classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # linear operation\n",
    "        y_pred = torch.addmm(self.bias1, x.view(list(x.size())[0], -1), self.weight1.t())\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "X_train=np.float32(np.expand_dims(X_train,-1))/255\n",
    "X_train=X_train.transpose((0,3,1,2))\n",
    "\n",
    "X_test=np.float32(np.expand_dims(X_test,-1))/255\n",
    "X_test=X_test.transpose((0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-UGSj6FqRKf"
   },
   "outputs": [],
   "source": [
    "# test the example linear classifier (note you should get around 90% accuracy\n",
    "# for 10 epochs and batchsize 50)\n",
    "linearClassifier = LinearClassifier()\n",
    "linearClassifier.train_net(X_train, y_train, epochs=10)\n",
    "\n",
    "print ('Linear classifier accuracy: %f'%test(X_test, y_test, linearClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RA5688oyNTu"
   },
   "outputs": [],
   "source": [
    "# display confusion matrix\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNzcCiLr0AU8"
   },
   "source": [
    "### Problem 2.3:  Visualizing Weights (Single Layer Perceptron) [3 pts]\n",
    "The simple linear classifier implemented in the cell already performs quite well. Plot the filter weights corresponding to each output class (weights, not biases) as images. (Normalize weights to lie between 0 and 1 and use color maps like 'inferno' or 'plasma' for good results). Comment on what the weights look like and why that may be so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8S3dYZgzzT_"
   },
   "outputs": [],
   "source": [
    "# Plot filter weights corresponding to each class, you may have to reshape them to make sense out of them\n",
    "# linearClassifier.weight1.data will give you the first layer weights\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmQUOBNg0PkW"
   },
   "source": [
    "#### Comments on weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJBWgsBE0S7K"
   },
   "source": [
    "### Problem 2.4: Multi Layer Perceptron (MLP) [8 pts]\n",
    "Here you will implement an MLP. The MLP must consist of 2 layers (weight multiplication and bias offset) that map to the following feature dimensions:\n",
    "\n",
    "* 28x28 -> hidden (50)\n",
    "* hidden (50) -> classes\n",
    "\n",
    "* The hidden layer must be followed with a ReLU nonlinearity. The final layer must not have a nonlinearity applied as we desire the raw logits output.\n",
    "* The final output of the computation graph must be stored in self.y as that will be used in the training.\n",
    "\n",
    "Display the confusion matrix and accuracy after training. Note: You should get ~95 % accuracy for 10 epochs and batch size 50.\n",
    "\n",
    "Plot the filter weights corresponding to the mapping from the inputs to the first 10 hidden layer outputs (out of 50). Do the weights look similar to the weights plotted in the previous problem? Why or why not?\n",
    "\n",
    "It is expected that the training model would take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ss2lUgpL0JRh"
   },
   "outputs": [],
   "source": [
    "class MLPClassifer(DNN):\n",
    "    def __init__(self, in_features=28*28, classes=10, hidden=50):\n",
    "        \"\"\"\n",
    "        Initialize weight and bias variables\n",
    "        \"\"\"\n",
    "        super(MLPClassifer, self).__init__()\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "\n",
    "mlpClassifer = MLPClassifer()\n",
    "mlpClassifer.train_net(X_train, y_train, epochs=10, batchSize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-4xraHl0muj"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "M_mlp,acc_mlp = Confusion(X_test, y_test, mlpClassifer)\n",
    "print ('MLP classifier accuracy: %f'%acc_mlp)\n",
    "VisualizeConfussion(M_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLD0yjHH0bVU"
   },
   "outputs": [],
   "source": [
    "# Plot filter weights\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBC6s9qQ1KKj"
   },
   "source": [
    "### Problem 2.5: Convolutional Neural Network (CNN) [8 pts]\n",
    "Here you will implement a CNN with the following architecture:\n",
    "\n",
    "* n=10\n",
    "* ReLU( Conv(kernel_size=5x5, stride=2, output_features=n) )\n",
    "* ReLU( Conv(kernel_size=5x5, stride=2, output_features=n*2) )\n",
    "* ReLU( Linear(hidden units = 64) )\n",
    "* Linear(output_features=classes)\n",
    "\n",
    "So, 2 convolutional layers, followed by 1 fully connected hidden layer and then the output layer\n",
    "\n",
    "Display the confusion matrix and accuracy after training. You should get around ~98 % accuracy for 10 epochs and batch size 50.<br><br>\n",
    "**Note: You are not allowed to use torch.nn.Conv2d() and torch.nn.Linear(), Using these will lead to deduction of points. Use the declared conv2d(), weight_variable() and bias_variable() functions.** Although, in practice, when you move forward after this class you will use torch.nn.Conv2d() which makes life easier and hides all the operations underneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OhmF0NM1Clj"
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, stride, bias=None):\n",
    "    # x: input\n",
    "    # W: weights (out, in, kH, kW)\n",
    "    return F.conv2d(x, W, bias, stride=stride, padding=2)\n",
    "\n",
    "# Defining a Convolutional Neural Network\n",
    "class CNNClassifer(DNN):\n",
    "    def __init__(self, classes=10, n=5):\n",
    "        super(CNNClassifer, self).__init__()\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "    def forward(self, x):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "       \n",
    "        return y \n",
    "cnnClassifer = CNNClassifer()\n",
    "cnnClassifer.train_net(X_train, y_train, epochs=10, batchSize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWkNhBgf1Sf3"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix and print the test accuracy of the classifier\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHx9gSiK1xVp"
   },
   "source": [
    "* Note that the MLP/ConvNet approaches lead to an accuracy a little higher than the K-NN approach. \n",
    "* In general, Neural net approaches lead to significant increase in accuracy, but in this case since the problem is not too hard, the increase in accuracy is not very high.\n",
    "* However, this is still quite significant considering the fact that the ConvNets we've used are relatively simple while the accuracy achieved using K-NN is with a search over 60,000 training images for every test image.\n",
    "* You can look at the performance of various machine learning methods on this problem at http://yann.lecun.com/exdb/mnist/\n",
    "* You can learn more about neural nets/ pytorch at<br> https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "* You can play with a demo of neural network created by Daniel Smilkov and Shan Carter at https://playground.tensorflow.org/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "jZQQIiKPnRQF",
    "aYf3GsdmpfvS",
    "6Wu-weDbqEAY",
    "mNzcCiLr0AU8",
    "zmQUOBNg0PkW",
    "7pCLEVJ_1F66"
   ],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
