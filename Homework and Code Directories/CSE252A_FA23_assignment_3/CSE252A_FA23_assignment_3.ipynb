{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deacce71",
   "metadata": {},
   "source": [
    "# CSE 252A Computer Vision I Fall 2023 - Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec3e6b9",
   "metadata": {},
   "source": [
    "Instructor: Ben Ochoa\n",
    "\n",
    "Due: Wed, Nov 22, 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0d730",
   "metadata": {},
   "source": [
    "**Name:**\n",
    "\n",
    "**PID:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c91f8cc",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Please answer the questions below using Python in the attached Jupyter notebook and follow the guidelines below:\n",
    " \n",
    "- This assignment must be completed **individually**. For more details, please follow the Academic Integrity Policy and Collaboration Policy on [Canvas](https://canvas.ucsd.edu).\n",
    "\n",
    "- All the solutions must be written in this Jupyter notebook.\n",
    "\n",
    "- You may use basic algebra packages (e.g., `NumPy`, `SciPy`, etc) but you are not allowed to use the packages that directly solve the problems. Feel free to ask the instructor and the teaching assistants if you are unsure about the packages to use.\n",
    "\n",
    "- It is highly recommended that you begin working on this assignment early.\n",
    "\n",
    "- **You must submit 3 files on Gradescope - `.pdf` , `.ipynb` and `.py` file where the .py file is the conversion of your .ipynb to .py file . You must mark each problem on Gradescope in the pdf.** \n",
    "    To convert the notebook to PDF, you can choose one way below:\n",
    "\n",
    "    1. You can print the web page and save as PDF (e.g., Chrome: Right click the web page $\\rightarrow$ Print... $\\rightarrow$ Choose \"Destination: Save as PDF\" and click \"Save\").\n",
    "\n",
    "    2. You can find the export option in the header: File $\\rightarrow$ Download as $\\rightarrow$ \"PDF via LaTeX\"\n",
    "\n",
    "    To convert the notebook (.ipynb) to .py file use the following command:\n",
    "\n",
    "<center> jupyter nbconvert --to script filename.ipynb --output output_filename.py </center>\n",
    "\n",
    "- Please make sure the content in each cell (e.g., code, output images, printed results, etc.) are clearly visible and are not cut-out or partially cropped in your final PDF file.\n",
    "\n",
    "- While submitting on gradescope, please make sure to assign the relevant pages in your PDF submission for each problem.\n",
    "\n",
    "**Late Policy:** Assignments submitted late will receive a 15% grade reduction for each 12 hours late (i.e., 30% per day). Assignments will not be accepted 72 hours after the due date. If you require an extension (for personal reasons only) to a due date, you must request one as far in advance as possible. Extensions requested close to or after the due date will only be granted for clear emergencies or clearly unforeseeable circumstances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec588b3",
   "metadata": {},
   "source": [
    "## Problem 1: Multiscale image representations [15 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fcf495",
   "metadata": {},
   "source": [
    "In the [Lecture 9](https://cseweb.ucsd.edu/classes/fa23/cse252A-a/lec9.pdf), given an image, we compare its multiscale representation generated by **Gaussian Image Pyramid** and **Scale-space** methods. The task for this problem is to first build multiscale representations for image `p1/pokemon.jpg`, then **comment on** your results obtained by generating a Gaussian pyramid for an image versus those obtained by generating its scale-space representation.\n",
    "\n",
    "For the Gaussian pyramid, use a binomial kernel of size 5x5 as an approximation for the Gaussian filter. The sampling rate between levels is $rate=2$. \n",
    "\n",
    "For the scale-space representation, use a Gaussian filter where the standard deviation depends on the corresponding level of the pyramid (**Hint:** standard deviation $\\sigma =  2^{level-1}$, for $level>0$). \n",
    "\n",
    "Look at the lecture slides to see the correspondence between pyramid levels and standard deviation for the Gaussian filter in scale space. Also, remember the Gaussian filter dimension is $\\lceil 6 \\sigma \\rceil$ for standard deviation $\\sigma$. If the result is an even number, then add 1 to make it odd. \n",
    "\n",
    "**Note:** Use border mirror padding on input images when applying filters and make sure that the image size remains constant.\n",
    "\n",
    "You need to construct the pyramid and scale-space representation from level 0 to level 9. Note that level 0 is just the original image in both the representations.\n",
    "\n",
    "Use the provided plotting function to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31273ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imageio.v2 import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import convolve\n",
    "import scipy.special\n",
    "import copy\n",
    "\n",
    "def gaussian2d(sig):\n",
    "    \"\"\"\n",
    "    Creates 2D Gaussian kernel with a sigma of `sig`.\n",
    "    \"\"\"\n",
    "    filter_size = int(sig * 6)\n",
    "    if filter_size % 2 == 0:\n",
    "        filter_size += 1\n",
    "        \n",
    "    ax = np.arange(-filter_size // 2 + 1., filter_size // 2 + 1.)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sig))\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def binomial_kernel(size):\n",
    "    \"\"\"Creates a binomial filter kernel\"\"\"\n",
    "    coeffs = np.array([scipy.special.binom(size, i) for i in range(size+1)]).reshape((-1,1))\n",
    "    kernel = np.repeat(coeffs, repeats=size+1, axis=1).T\n",
    "    kernel = kernel * coeffs\n",
    "    return kernel/np.sum(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffbc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pyramid(img, num_levels = 9):\n",
    "    \"\"\"This function construct the gaussian pyramid for the input image.\n",
    "\n",
    "    Args:\n",
    "    img: original image (level-0)\n",
    "    num_levels: number of levels to generate (level-0 not included)\n",
    "    \n",
    "    Returns:\n",
    "    pyramid: the pyramid as a list consisting of all level images.\n",
    "             The first element of the list is the original image itself.\n",
    "    \"\"\"\n",
    "    \n",
    "    pyramid = []\n",
    "    pyramid.append(img.copy()) # level-0 image\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "    \n",
    "    return pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_space(img, num_levels = 9):\n",
    "    \"\"\"This function construct the scale-space representation for the input image.\n",
    "\n",
    "    Args:\n",
    "    img: original image (level-0)\n",
    "    num_levels: number of levels to generate (level-0 not included)\n",
    "    \n",
    "    Returns:\n",
    "    scale_space: the scale space as a list consisting of all the images in the scale space\n",
    "             The first element of the list is the original image itself.\n",
    "    \"\"\"\n",
    "    \n",
    "    scale_space = []\n",
    "    scale_space.append(img.copy()) # std = 0, level-0 image\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "\n",
    "    return scale_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(pyramid, scale_space):        \n",
    "    \n",
    "    print(\"\\t\\tGaussian Pyramid\\t\\t\\t Scale Space Representation\")\n",
    "    \n",
    "    N = len(pyramid)\n",
    "    std_list = [0] + [2**i for i in range(N-1)]\n",
    "    for i in range(N):\n",
    "        pyramid_img = pyramid[i]\n",
    "        scale_space_img = scale_space[i]\n",
    "        \n",
    "        fig = plt.figure(figsize=(12, 9))\n",
    "        \n",
    "        ax1 = fig.add_subplot(221)\n",
    "        ax1.imshow(pyramid_img)\n",
    "        ax1.axis('off')\n",
    "        plt.title(\"Level {}\".format(i))\n",
    "        \n",
    "        ax2 = fig.add_subplot(222)\n",
    "        ax2.imshow(scale_space_img)\n",
    "        ax2.axis('off')\n",
    "        plt.title(\"Standard Deviation = {}\".format(std_list[i]))\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea5d7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from imageio.v2 import imread\n",
    "\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "img = imread(\"p1/pokemon.jpg\")\n",
    "\n",
    "plot_results(pyramid, scale_space_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c139c51",
   "metadata": {},
   "source": [
    "**Comments on your results:**\n",
    "\n",
    "----------->YOUR COMMENTS HERE<------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------->COMMENTS END<------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544dfb02",
   "metadata": {},
   "source": [
    "## Problem 2: Epipolar Geometry | Uncalibrated Stereo [40 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d7b46",
   "metadata": {},
   "source": [
    "In Assignment 2, we worked with calibrated cameras (i.e., calibration matrices $K_1$ and $K_2$, camera rotation matrices $R_1$ and $R_2$, camera translation vectors $t_1$ and $t_2$) to solve calibrated stereo. \n",
    "\n",
    "In this problem, we are interested in recovering the stereo information without the use of a calibration process. Specifically, given ground-truth correspondences from a pair of images, your task is to estimate the fundamental matrix and recover the epipolar geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5ce9c",
   "metadata": {},
   "source": [
    "### Problem 2.1 Fundamental matrix [12 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea390ff",
   "metadata": {},
   "source": [
    "Complete the `compute_fundamental` function below using the 8-point algorithm described in lecture. Note that the normalization of the corner points is handled in the `fundamental_matrix` function.\n",
    "\n",
    "**Hint:** Feel free to use any basic Python packages to solve the singular value decomposition. However, read the corresponding documentation to make sure about the form of parameters and returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d58db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental(x1, x2):\n",
    "    \"\"\"    \n",
    "    Computes the fundamental matrix from corresponding points using the 8 point algorithm.\n",
    "    Args:\n",
    "        x1: normalized homogeneous matching points from image1 (3xN)\n",
    "        x2: normalized homogeneous matching points from image2 (3xN)\n",
    "    Returns:\n",
    "        F: Fundamental Matrix (3x3)\n",
    "    \"\"\"\n",
    "    \n",
    "    F = np.ones((3,3))\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "    return F\n",
    "\n",
    "def fundamental_matrix(x1,x2):\n",
    "    \"\"\"    \n",
    "    Computes the fundamental matrix from corresponding points\n",
    "    \n",
    "    Args:\n",
    "        x1: unnormalized homogeneous points from image1 (3xN)\n",
    "        x2: unnormalized homogeneous points from image2 (3xN)\n",
    "        \n",
    "    Returns:\n",
    "        Fundamental Matrix (3x3)\n",
    "    \"\"\"\n",
    "        \n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don't match.\")\n",
    "\n",
    "    # normalize image coordinates\n",
    "    x1 = x1 / x1[2]\n",
    "    mean_1 = np.mean(x1[:2],axis=1)\n",
    "    S1 = np.sqrt(2) / np.std(x1[:2])\n",
    "    T1 = np.array([[S1,0,-S1*mean_1[0]],[0,S1,-S1*mean_1[1]],[0,0,1]])\n",
    "    x1 = np.dot(T1,x1)\n",
    "    \n",
    "    x2 = x2 / x2[2]\n",
    "    mean_2 = np.mean(x2[:2],axis=1)\n",
    "    S2 = np.sqrt(2) / np.std(x2[:2])\n",
    "    T2 = np.array([[S2,0,-S2*mean_2[0]],[0,S2,-S2*mean_2[1]],[0,0,1]])\n",
    "    x2 = np.dot(T2,x2)\n",
    "\n",
    "    # compute F with the normalized coordinates\n",
    "    F = compute_fundamental(x1,x2)\n",
    "\n",
    "    # reverse normalization\n",
    "    F = np.dot(T2.T,np.dot(F,T1))\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86474d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CODE, DO NOT MODIFY\n",
    "# Here is the code for you to test your implementation\n",
    "# Here, we are using only the first 12 correspondences from the dataset, to test our fundamental matrix\n",
    "cor1 = np.load(\"./p2/\"+'warrior'+\"/cor1.npy\")[:, :12]\n",
    "cor2 = np.load(\"./p2/\"+'warrior'+\"/cor2.npy\")[:, :12]\n",
    "\n",
    "F = fundamental_matrix(cor1, cor2)\n",
    "\n",
    "# For grading purposes only\n",
    "F = F/np.linalg.norm(F)\n",
    "print(F/F[2,2])\n",
    "\n",
    "\n",
    "\n",
    "# should print \n",
    "# [[-2.51708785e-06 -1.17650275e-05  1.23246540e-02]\n",
    "#  [ 8.11218437e-06 -1.18621082e-06  2.21900551e-02]\n",
    "#  [-1.15513368e-02 -1.88996905e-02  1.00000000e+00]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54891591",
   "metadata": {},
   "source": [
    "### Problem 2.2 Epipoles [6 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce0075",
   "metadata": {},
   "source": [
    "In this part, you are supposed to complete the function <code>compute_epipole</code> to calculate the epipoles for a given fundamental matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71790f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epipole(F):\n",
    "    \"\"\"\n",
    "    This function computes the epipoles for a given fundamental matrix.\n",
    "    \n",
    "    Args:\n",
    "      F: fundamental matrix\n",
    "      \n",
    "    Returns:\n",
    "      e1: corresponding epipole in image1\n",
    "      e2: corresponding epipole in image2\n",
    "    \"\"\"\n",
    "    e1 = np.array([0, 0, 0])\n",
    "    e2 = np.array([0, 0, 0])\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "\n",
    "    return e1,e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54afec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CODE, DO NOT MODIFY\n",
    "# Here is the code for you to test your implementation\n",
    "F_test = np.array([[1, 7, 2], [8, 8, 2], [-6, 6, 2]])\n",
    "\n",
    "e1,e2 = compute_epipole(F_test)\n",
    "\n",
    "# For grading purposes only\n",
    "e1 /= e1[-1]\n",
    "e2 /= e2[-1]\n",
    "\n",
    "print(e1)\n",
    "print(e2)\n",
    "\n",
    "# should print \n",
    "# [ 0.04166667 -0.29166667  1.        ] \n",
    "# [-2.  1.  1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c40dd8",
   "metadata": {},
   "source": [
    "### Problem 2.3: Epipolar Lines [12 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b3c9e",
   "metadata": {},
   "source": [
    "For this part, given pairs of images, your task is to plot the epipolar lines in both images for each image pair. You will want to complete the function <code>plot_epipolar_lines</code> using the `fundamental_matrix` function you just got. \n",
    " \n",
    "The figure below gives you an idea on how the final results look on **dino**. Show your results for **matrix** and **warrior**.\n",
    "<!--- ![Dino Epipolar](fig/eg_dino_epipolar_lines.png) --->\n",
    "<!--- The previous results in export to pdf errors on some systems but the following does not --->\n",
    "<img src=\"fig/eg_dino_epipolar_lines.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6977cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epipolar_lines(img1, img2, F, cor1, cor2):\n",
    "    \"\"\"Plot epipolar lines on image given image, corners\n",
    "\n",
    "    Args:\n",
    "        img1: Image 1.\n",
    "        img2: Image 2.\n",
    "        F:    Fundamental matrix\n",
    "        cor1: Corners in homogeneous image coordinates in image 1 (3xN)\n",
    "        cor2: Corners in homogeneous image coordinates in image 2 (3xN)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert cor1.shape[0] == 3\n",
    "    assert cor2.shape[0] == 3\n",
    "    assert cor1.shape == cor2.shape\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT CHANGE\n",
    "# This code is for you to plot the results. \n",
    "# The total number of outputs is 4 images in 2 pairs\n",
    "\n",
    "imgids = [\"matrix\", \"warrior\"]\n",
    "for imgid in imgids:\n",
    "    I1 = imread(\"./p2/\"+imgid+\"/\"+imgid+\"0.png\")\n",
    "    I2 = imread(\"./p2/\"+imgid+\"/\"+imgid+\"1.png\")\n",
    "    cor1 = np.load(\"./p2/\"+imgid+\"/cor1.npy\")\n",
    "    cor2 = np.load(\"./p2/\"+imgid+\"/cor2.npy\")\n",
    "    F = fundamental_matrix(cor1, cor2)\n",
    "    plot_epipolar_lines(I1,I2,F,cor1,cor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5c57a",
   "metadata": {},
   "source": [
    "### Problem 2.4: Uncalibrated Stereo Image Rectification [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f045f5a",
   "metadata": {},
   "source": [
    "In Assignment 2, you performed epipolar rectification with calibrated stereo cameras. Rectifying a pair of images can also be done for uncalibrated camera images. Using the fundamental matrix we can find the pair of epipolar lines $\\boldsymbol{l_i}$ and $\\boldsymbol{l^{'}_i}$ for each of the correspondences. The intersection of these lines will give us the respective epipoles $\\boldsymbol{e}$ and $\\boldsymbol{e^{'}}$. Now to make the epipolar lines to be parallel we need to map the epipoles to infinity. Hence, we need to find a homography that maps the epipoles to infinity.\n",
    " \n",
    "The rectificaton method has already been implemented for you. You can get more details from the paper *Theory and Practice of Projective Rectification* by Richard Hartley.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "1) complete the `warp_image` function (**Hint:** You may reuse some of the codes from Homework2, but this time we perform the warp of the full image content. The size of the output image is bounded by the **bounding box**).\n",
    "\n",
    "2) use the given `image_rectification` function to find the rectified images\n",
    "\n",
    "3) plot the parallel epipolar lines using the `plot_epipolar_lines` function from above.\n",
    "\n",
    "The figure below gives you an idea on how the final results look (Note that the two images may not be in the same shape). Show your result for **matrix** and **warrior**.\n",
    "<!--- ![House Rectification](fig/exp_house_rectify.png) --->\n",
    "<!--- The previous results in export to pdf errors on some systems but the following does not --->\n",
    "<img src=\"fig/exp_house_rectify.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abedcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(image, H):\n",
    "    \"\"\"\n",
    "    Performs the warp of the full image content.\n",
    "    Calculates bounding box by piping four corners through the transformation.\n",
    "    \n",
    "    Args: \n",
    "    image: Image to warp\n",
    "    H: The image rectification transformation matrices.\n",
    "    \n",
    "    Returns:\n",
    "    Out: An inverse warp of the image, given a homography.\n",
    "    min_x, min_y: The minimum/maxmum of warped image bound.\n",
    "    \"\"\"\n",
    "#     out_height, out_width = max_y - min_y, max_x - min_x\n",
    "\n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "    return out, min_x, min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "\n",
    "def compute_matching_homographies(e2, F, im2, points1, points2):\n",
    "    \"\"\"This function computes the homographies to get the rectified images.\n",
    "    \n",
    "    Args: \n",
    "    e2: epipole in image 2\n",
    "    F: the fundamental matrix (think about what you should be passing: F or F.T!)\n",
    "    im2: image2\n",
    "    points1: corner points in image1\n",
    "    points2: corresponding corner points in image2\n",
    "    \n",
    "    Returns:\n",
    "    H1: homography for image 1\n",
    "    H2: homography for image 2\n",
    "    \"\"\"\n",
    "    # calculate H2\n",
    "    width = im2.shape[1]\n",
    "    height = im2.shape[0]\n",
    "\n",
    "    T = np.identity(3)\n",
    "    T[0][2] = -1.0 * width / 2\n",
    "    T[1][2] = -1.0 * height / 2\n",
    "\n",
    "    e2hat = T.dot(e2) \n",
    "\n",
    "    norm_v = np.linalg.norm(e2hat[:2])\n",
    "    cos_theta = e2hat[0] / norm_v\n",
    "    sin_theta = e2hat[1] / norm_v\n",
    "\n",
    "    if cos_theta < 0:\n",
    "        cos_theta = -cos_theta\n",
    "        sin_theta = -sin_theta\n",
    "\n",
    "    R = np.array([[cos_theta, sin_theta, 0],\n",
    "                  [-sin_theta, cos_theta, 0],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "    G = np.identity(3)\n",
    "    G[2, 0] = -e2hat[2] / (e2hat[0] * cos_theta + e2hat[1] * sin_theta)\n",
    "\n",
    "    H2 = np.dot(np.dot(G, R), T)\n",
    "    \n",
    "    \n",
    "    # calculate H1\n",
    "    e_prime = np.zeros((3, 3))\n",
    "    e_prime[0][1] = -e2[2]\n",
    "    e_prime[0][2] = e2[1]\n",
    "    e_prime[1][0] = e2[2]\n",
    "    e_prime[1][2] = -e2[0]\n",
    "    e_prime[2][0] = -e2[1]\n",
    "    e_prime[2][1] = e2[0]\n",
    "\n",
    "    v = np.array([1, 1, 1])\n",
    "    M = e_prime.dot(F) + np.outer(e2, v)\n",
    "\n",
    "    points1_hat = H2.dot(M.dot(points1.T)).T\n",
    "    points2_hat = H2.dot(points2.T).T\n",
    "\n",
    "    W = points1_hat / points1_hat[:, 2].reshape(-1, 1)\n",
    "    b = (points2_hat / points2_hat[:, 2].reshape(-1, 1))[:, 0]\n",
    "\n",
    "    # least square problem\n",
    "    a1, a2, a3 = np.linalg.lstsq(W, b, rcond=None)[0]\n",
    "    HA = np.identity(3)\n",
    "    HA[0] = np.array([a1, a2, a3])\n",
    "\n",
    "    H1 = HA.dot(H2).dot(M)\n",
    "    return H1, H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03600dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_rectification(im1, im2, points1, points2):\n",
    "    \"\"\"This function provides the rectified images along with the new corner points as\n",
    "    images with corner correspondences\n",
    "    \n",
    "    Args:\n",
    "    im1: image1\n",
    "    im2: image2\n",
    "    points1: corner points in image1\n",
    "    points2: corner points in image2\n",
    "    \n",
    "    Returns:\n",
    "    rectified_im1: rectified image 1\n",
    "    rectified_im2: rectified image 2\n",
    "    new_cor1: new corners in the rectified image 1\n",
    "    new_cor2: new corners in the rectified image 2\n",
    "    \"\"\"\n",
    "    F = fundamental_matrix(points1, points2)\n",
    "    e1, e2 = compute_epipole(F)\n",
    "    H1, H2 = compute_matching_homographies(e2, F, im2, points1.T, points2.T)\n",
    "    \n",
    "    # Apply homographies\n",
    "    rectified_im1, min_x1, min_y1 = warp_image(im1, H1)\n",
    "    rectified_im2, min_x2, min_y2 = warp_image(im2, H2)\n",
    "\n",
    "    new_cor1 = np.dot(H1, points1) # 3 x n\n",
    "    new_cor1 /= new_cor1[-1, :]\n",
    "    new_cor1[0, :] -= min_x1\n",
    "    new_cor1[1, :] -= min_y1\n",
    "    new_cor2 = np.dot(H2, points2)\n",
    "    new_cor2 /= new_cor2[-1, :]\n",
    "    new_cor2[0, :] -= min_x2\n",
    "    new_cor2[1, :] -= min_y2\n",
    "    return rectified_im1, rectified_im2, new_cor1, new_cor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for you to plot the results. \n",
    "# The total number of outputs is 4 images in 2 pairs\n",
    "\n",
    "imgids = [\"matrix\", \"warrior\"]\n",
    "for imgid in imgids:\n",
    "    print(\"./p2/\"+imgid+\"/\"+imgid+\"0.png\")\n",
    "    I1 = imread(\"./p2/\"+imgid+\"/\"+imgid+\"0.png\")\n",
    "    I2 = imread(\"./p2/\"+imgid+\"/\"+imgid+\"1.png\")\n",
    "    \n",
    "    cor1 = np.load(\"./p2/\"+imgid+\"/cor1.npy\")\n",
    "    cor2 = np.load(\"./p2/\"+imgid+\"/cor2.npy\")\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c084eee",
   "metadata": {},
   "source": [
    "## Problem 3: Fundamental Matrix Estimation with RANSAC [40 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be5cd6",
   "metadata": {},
   "source": [
    "In problem 2, you have `fundamental_matrix` function which calculates the fundamental matrix $F$ from matching pairs of points in two different images. In this problem, we will first implement a SIFT (Scale-Invariant Feature Transform)-pipeline that detects feature points and identifies matching points between two images. Then we estimate the fundamental matrix $F$ with those matching points using RANSAC method.\n",
    "\n",
    "**Instruction:** You can use basic functions/objects in OpenCV, but you **may not use** functions that directly solve the problem unless specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e88a0",
   "metadata": {},
   "source": [
    "### Problem 3.1: SIFT Feature Detection [5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f45eb",
   "metadata": {},
   "source": [
    "Let's get some experience with SIFT detection. You may refer to [SIFT Python tutorial](https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html) and OpenCV [cv::SIFT Class Reference](https://docs.opencv.org/4.x/d7/d60/classcv_1_1SIFT.html) according to your OpenCV version. For more details and understanding, reading [the original paper](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf) is highly recommended. \n",
    "\n",
    "The following example plots keypoints on `p2/dino/dino0.png`. Your task is to plot a similar image for `p2/dino/dino1.png`.\n",
    "<center><img src=\"fig/eg_dino_sift.png\" alt=\"DINO SIFT\" width=\"400\" align=\"center\"/></center>\n",
    "\n",
    "**For this part ONLY (Problem 3.1), you will use any OpenCV functions you need.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e964d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def get_sift_features_plot(image):\n",
    "    \"\"\"This function draws SIFT features\n",
    "    \n",
    "    Args:\n",
    "    image:rgb image\n",
    "    \n",
    "    Returns:\n",
    "    keypoint_image: image with key points drawn on\n",
    "    \"\"\"\n",
    "    keypoint_image = image.copy()\n",
    "        \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "\n",
    "    return keypoint_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6de9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT CHANGE\n",
    "# This code is for you to plot the results. \n",
    "image = imread('p2/dino/dino1.png')\n",
    "keypointimage = get_sift_features_plot(image)\n",
    "plt.imshow(keypointimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818e00f",
   "metadata": {},
   "source": [
    "### Problem 3.2: SIFT Feature Matching [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacebabd",
   "metadata": {},
   "source": [
    "Let's try to match the SIFT features from a pair of images. You will be using [cv::BFMatcher](https://docs.opencv.org/4.x/d3/da1/classcv_1_1BFMatcher.html), a Brute-force descriptor matcher in OpenCV. Also, we will draw lines between the features that match in both the images like you did in Homework 2. However, you will use [OpenCV Drawing Functions](https://docs.opencv.org/4.x/d6/d6e/group__imgproc__draw.html) this time.\n",
    "Complete the `get_matches_sift` and `create_matching_image` functions to draw a pair of matched images. The following example plots the result for **dino**, your task is to plot the result for **skull-book**.\n",
    "<!--- ![DINO MATCHING](fig/eg_dino_sift_matching.png) --->\n",
    "<!--- The previous results in export to pdf errors on some systems but the following does not --->\n",
    "<img src=\"fig/eg_dino_sift_matching.png\">\n",
    "For this part (Problem 3.2), you will use `cv::BFMatcher` and `cv::SIFT` related modules from OpenCV library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab419bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_sift(img1, img2):\n",
    "    \"\"\"This function detects matching points from a pair of images\n",
    "        using SIFT feature detection and Brute force descriptor matcher.\n",
    "    Args:\n",
    "        img1: Grayscale image1\n",
    "        img2: Grayscale image2\n",
    "    Returns:\n",
    "        corners1: numpy array that contains matching corners from image1 in image coordinates (Nx2)\n",
    "        corners2: numpy array that contains matching corners from image2 in image coordinates (Nx2)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "    return corners1, corners2\n",
    "\n",
    "def create_matching_image(img1, img2, corners1, corners2):\n",
    "    \"\"\"This function create a matching result image from a pair of images\n",
    "       and their correspondences.\n",
    "    Args:\n",
    "        img1: rgb image1\n",
    "        img2: rgb image2\n",
    "        corners1: matching points in image1 in image coordinates (Nx2)\n",
    "        corners2: matching points in image2 in image coordinates (Nx2)\n",
    "    Returns:\n",
    "        matching_img: the result rgb matching image. \n",
    "    \"\"\"\n",
    "    \n",
    "    h1, w1, _ = img1.shape;h2, w2, _ = img2.shape;\n",
    "    height = max(h1, h2); width = w1+w2\n",
    "    matching_img = np.zeros((height, width, 3), dtype=img1.dtype)\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "        \n",
    "    return matching_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT CHANGE\n",
    "# This code is for you to plot the results. \n",
    "\n",
    "# read images\n",
    "img1 = imread('p3/skull-book1.jpg')  \n",
    "img2 = imread('p3/skull-book2.jpg') \n",
    "\n",
    "corners1, corners2 = get_matches_sift(cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY),\\\n",
    "                                      cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY))\n",
    "\n",
    "print('Found {:d} possibly matching features'.format(corners1.shape[0]))\n",
    "match_image = create_matching_image(img1, img2, corners1, corners2)\n",
    "plt.figure(figsize=(16,8));plt.imshow(match_image); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21694ac",
   "metadata": {},
   "source": [
    "### Problem 3.3: Calculate the Fundamental Matrix using RANSAC [25 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de93d7",
   "metadata": {},
   "source": [
    "Now you have `fundamental_matrix` function which calculates the fundamental matrix $F$ and a set of potential matching points using SIFT and BFMatcher. However, as you see from Problem 3.2, unlike the Problem 2, the SIFT-pipeline doesn't guarantee that those points are perfectly matched. Therefore, we will implement the RANdom SAmple Consensus (RANSAC) method from the lecture to search through the potential matching points and remove those false-matches (outliers) to use for calculating the fundamental matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e7351",
   "metadata": {},
   "source": [
    "Complete `fundamental_matrix_ransac` to estimate fundamental matrix with RANSAC method. You will implement `compute_consensus_set` as a building block to find a consensus set. You will also complete functions to calculate distance as points to epipolar line distance (`point2line_dist`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_homog(points):\n",
    "    \"\"\"convert points from euclidean to homogeneous\n",
    "    \"\"\"\n",
    "    m, n = points.shape\n",
    "    homo_points = np.vstack((points, np.ones(n)))\n",
    "    return homo_points\n",
    "\n",
    "def point2line_dist(point, line):\n",
    "    \"\"\"This function provides distance of point to (epipolar) line\n",
    "    Args:\n",
    "        point: 2D homogeneous point\n",
    "        line: (a,b,c) for ax+by+c=0\n",
    "    Returns:\n",
    "        distance: distance of point to line\n",
    "    \"\"\"\n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "\n",
    "    return distance\n",
    "\n",
    "def compute_consensus_set(x1, x2, F, threshold):\n",
    "    \"\"\"This function find consensus set of points for current F\n",
    "    Args:\n",
    "        x1: homogeneous points from image1 (3xN)\n",
    "        x2: homogeneous points from image2 (3xN)\n",
    "        F: fundamental matrix\n",
    "        threshold: the maximum distance allowed for a correspondence\n",
    "    Returns:\n",
    "        inliers: numpy array that contains indices of the inliers in x1 and x2\n",
    "    \"\"\"\n",
    "    inliers = []\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "            \n",
    "            \n",
    "    return np.array(inliers)  \n",
    "    \n",
    "def compute_N(p, s, inlier_p):\n",
    "    if inlier_p>0.99:\n",
    "        return 0\n",
    "    return int(np.log(1 - p) / np.log(1 - inlier_p ** s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38146ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fundamental_matrix_ransac(x1, x2, threshold=100, confidence=0.95, iter_limit=5000):\n",
    "    \"\"\"    \n",
    "    Computes the fundamental matrix with RANSAC\n",
    "    Use RANSAC to find the best fundamental matrix by randomly sampling interest points.\n",
    "    Args:\n",
    "        x1: possibly matching points from image1 (2xN)\n",
    "        x2: possibly matching points from image2 (2xN)\n",
    "        threshold: distance threshold\n",
    "        confidence: confidence value, 0.95 by default\n",
    "        iter_limit: maximum iterations to force running stop\n",
    "        \n",
    "    Returns:\n",
    "        best_F: the best Fundamental Matrix (3x3)\n",
    "        x1_inliers: A numpy array (2xM) representing the true match points (inliers)\n",
    "                    from the image1 with respect to best_F\n",
    "        x2_inliers: A numpy array (2xM) representing the true match points (inliers)\n",
    "                    from the image2 with respect to best_F        \n",
    "    \"\"\"\n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "    print('Total Number of inliers {}'.format(max_inliers))\n",
    "    return best_F, x1_inliers, x2_inliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfeaf7b",
   "metadata": {},
   "source": [
    "First, test your implementation on **matrix** with ground truth matches. The two pairs of images 1) the matching pair with F estimated from the whole set set of corners and 2) the matching pair with F estimated with RANSAC method. The two matching pairs should look very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT CHANGE\n",
    "# This code is for you to plot the results. \n",
    "\n",
    "imgids = [\"matrix\"]\n",
    "for imgid in imgids:\n",
    "    print(\"./p2/\"+imgid+\"/\"+imgid+\"0.png\")\n",
    "    I1 = imread(\"./p2/\"+imgid+\"/\"+imgid+\"0.png\")\n",
    "    I2 = imread(\"./p2/\"+imgid+\"/\"+imgid+\"1.png\")\n",
    "    \n",
    "    cor1 = np.load(\"./p2/\"+imgid+\"/cor1.npy\")\n",
    "    cor2 = np.load(\"./p2/\"+imgid+\"/cor2.npy\")\n",
    "    \n",
    "    print('Found {:d} possibly matching features'.format(cor1.shape[1]))\n",
    "    \n",
    "    match_image_all = create_matching_image(I1, I2, cor1.T, cor2.T)\n",
    "    \n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.subplot(1,2,1); plt.imshow(match_image_all);\n",
    "\n",
    "    F, x1_in, x2_in = fundamental_matrix_ransac(cor1[:2,:], cor2[:2,:])\n",
    "    match_image = create_matching_image(I1, I2, x1_in.T, x2_in.T)\n",
    "    print('\\n\\tF estimated with whole set of points\\t\\t\\t\\t F estimated with RANSAC')\n",
    "    \n",
    "    plt.subplot(1,2,2); plt.imshow(match_image); plt.show()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f3d329",
   "metadata": {},
   "source": [
    "Then, show your results for **skull-book**. You can tweak the parameters to `fundamental_matrix_ransac` to optimize your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT CHANGE\n",
    "# This code is for you to plot the results.  \n",
    "\n",
    "def plot_matching_origin(I1, I2, corners1, corners2):\n",
    "    match_image_all = create_matching_image(I1, I2, corners1, corners2)\n",
    "    print('\\n F estimated with whole set of points')\n",
    "    plt.figure(figsize=(16,8)); plt.imshow(match_image_all)\n",
    "\n",
    "def plot_matching_RANSAC(I1, I2, corners1, corners2, thresh):\n",
    "    F, x1_in, x2_in = fundamental_matrix_ransac(corners1.T, corners2.T, threshold=thresh)\n",
    "    match_image = create_matching_image(I1, I2, x1_in.T, x2_in.T)\n",
    "    print('F estimated with RANSAC, Dist threshold='+str(thresh))\n",
    "    plt.figure(figsize=(16,8)); plt.imshow(match_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4411007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CODE: DO NOT MODIFY\n",
    "I1 = imread(\"./p3/skull-book1.jpg\");scale_a=0.5;\n",
    "I2 = imread(\"./p3/skull-book2.jpg\");scale_b=0.5;\n",
    "\n",
    "I1 = cv2.resize(I1, \\\n",
    "                (int(I1.shape[1] * scale_a), int(I1.shape[0] * scale_a)),\\\n",
    "                interpolation = cv2.INTER_AREA)\n",
    "I2 = cv2.resize(I2, \\\n",
    "                (int(I2.shape[1] * scale_b), int(I2.shape[0] * scale_b)),\\\n",
    "                interpolation = cv2.INTER_AREA)\n",
    "\n",
    "corners1, corners2 = get_matches_sift(cv2.cvtColor(I1, cv2.COLOR_RGB2GRAY),\\\n",
    "                                  cv2.cvtColor(I2, cv2.COLOR_RGB2GRAY))\n",
    "print('Found {:d} possibly matching features'.format(corners1.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439aa0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT MODIFY\n",
    "\n",
    "plot_matching_origin(I1, I2, corners1, corners2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 20 #You can tweak this\n",
    "\n",
    "#PLOT CODE: DO NOT MODIFY\n",
    "plot_matching_RANSAC(I1, I2, corners1, corners2, thresh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dab040",
   "metadata": {},
   "source": [
    "Using the SIFT and RANSAC functions that you have implemented, plot the epipolar lines and corners for both images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "I1 = imread(\"./p3/skull-book1.jpg\");scale_a=0.5;\n",
    "I2 = imread(\"./p3/skull-book2.jpg\");scale_b=0.5;\n",
    "\n",
    "I1 = cv2.resize(I1, \\\n",
    "                (int(I1.shape[1] * scale_a), int(I1.shape[0] * scale_a)),\\\n",
    "                interpolation = cv2.INTER_AREA)\n",
    "I2 = cv2.resize(I2, \\\n",
    "                (int(I2.shape[1] * scale_b), int(I2.shape[0] * scale_b)),\\\n",
    "                interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db870e2",
   "metadata": {},
   "source": [
    "## Problem 4: Optical Flow [15 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be79e2",
   "metadata": {},
   "source": [
    "In this problem, we will implement the multi-resolution Lucas-Kanade algorithm to estimate optical flow.\n",
    "\n",
    "An example optical flow output is shown below - this is not a solution, just an example output.\n",
    "\n",
    "<!--- ![title](fig/sample_optical_flow_output.PNG) --->\n",
    "<!--- The previous results in export to pdf errors on some systems but the following does not --->\n",
    "<img src=\"fig/sample_optical_flow_output.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f9cba",
   "metadata": {},
   "source": [
    "### Problem 4.1: Lucas-Kanade implementation [15 pts]\n",
    "\n",
    "Implement the Lucas-Kanade method for estimating optical ﬂow. Fill in the function `compute_LK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecfc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grayscale(img):\n",
    "    '''\n",
    "    Converts RGB image to Grayscale\n",
    "    '''\n",
    "    gray=np.zeros((img.shape[0],img.shape[1]))\n",
    "    gray=img[:,:,0]*0.2989+img[:,:,1]*0.5870+img[:,:,2]*0.1140\n",
    "    return gray\n",
    "\n",
    "def plot_optical_flow(img,U,V,titleStr):\n",
    "    '''\n",
    "    Plots optical flow given U,V and one of the images\n",
    "    '''\n",
    "    \n",
    "    # Change t if required, affects the number of arrows\n",
    "    # t should be between 1 and min(U.shape[0],U.shape[1])\n",
    "    t=10 \n",
    "    \n",
    "    # Subsample U and V to get visually pleasing output\n",
    "    U1 = U[::t,::t]\n",
    "    V1 = V[::t,::t]\n",
    "    \n",
    "    # Create meshgrid of subsampled coordinates\n",
    "    r, c = img.shape[0],img.shape[1]\n",
    "    cols,rows = np.meshgrid(np.linspace(0,c-1,c), np.linspace(0,r-1,r))\n",
    "    cols = cols[::t,::t]\n",
    "    rows = rows[::t,::t]\n",
    "    \n",
    "    # Plot optical flow\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img)\n",
    "    plt.quiver(cols,rows,U1,-V1)\n",
    "    plt.title(titleStr)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "for i in range(1,5):\n",
    "    # each image after converting to gray scale is of size -> 400x288\n",
    "    images.append(plt.imread('p4/im'+str(i)+'.png')[:,:288,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes simple Lucas-Kanade Optical Flow\n",
    "def compute_LK(img1, img2, window, u_prev=None, v_prev=None):\n",
    "    \"\"\"\n",
    "    img1 - grayscale image 1 (HxW)\n",
    "    img2 - grayscale image 2 (HxW)\n",
    "    window - size of the window (integer)\n",
    "    \n",
    "    \"\"\"\n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddf3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CODE: DO NOT MODIFY\n",
    "## Test your implementation on sample parameter values\n",
    "window = 45\n",
    "U, V = compute_LK(grayscale(images[0]),grayscale(images[1]), window)\n",
    "# Plot\n",
    "plot_optical_flow(images[0],U,V, 'window = '+str(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd006775",
   "metadata": {},
   "source": [
    "**Test with different Window size:**\n",
    "\n",
    "Plot optical ﬂow for the pair of images im1 and im2 for at least 4 diﬀerent window sizes which leads to observable diﬀerence in the results. We have provided the different window sizes. Comment on the eﬀect of window size on results and justify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023d371",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "windows=[10, 20, 40, 60]\n",
    "\n",
    "for i in range(4):\n",
    "    U,V=compute_LK(grayscale(images[0]),grayscale(images[1]),windows[i])\n",
    "    plot_optical_flow(images[0],U,V,'window size='+str(windows[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782f8a1",
   "metadata": {},
   "source": [
    "Your comments here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb358ca1",
   "metadata": {},
   "source": [
    "### Problem 4.2: Multi-resolution Lucas-Kanade implementation [Optional] [0 pts]\n",
    "\n",
    "**NOTE: This problem is optional. Your submission for this problem would be graded but you would not receive a score for solving this problem. However, you are welcome and encouraged to try it out and bring any questions that you have to the instructional team.**\n",
    "\n",
    "\n",
    "Implement the Lucas-Kanade method for estimating optical flow. The function `LucasKanadeMultiScale` needs to be completed. You can implement `upsample_flow` and `OpticalFlowRefine` as 2 building blocks in order to complete this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d37d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use interpolate from scipy\n",
    "# You can implement 'upsample_flow' and 'OpticalFlowRefine' \n",
    "# as 2 building blocks in order to complete this.\n",
    "def upsample_flow(u_prev, v_prev):\n",
    "    ''' You may implement this method to upsample optical flow from previous level\n",
    "    Args:\n",
    "        u_prev, v_prev: optical flow from prev level\n",
    "    Returns:\n",
    "        u, v: upsampled optical flow to the current level\n",
    "    '''\n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "\n",
    "    return u, v\n",
    "\n",
    "def OpticalFlowRefine(im1,im2,window, u_prev=None, v_prev=None):\n",
    "    '''\n",
    "    Inputs: the two images at current level and window size\n",
    "    u_prev, v_prev - previous levels optical flow\n",
    "    Return u,v - optical flow at current level\n",
    "    '''   \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "\n",
    "    return u, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def LucasKanadeMultiScale(im1,im2,window, numLevels=2):\n",
    "    '''\n",
    "    Implement the multi-resolution Lucas kanade algorithm\n",
    "    Inputs: the two images, window size and number of levels\n",
    "    if numLevels = 1, then compute optical flow at only the given image level.\n",
    "    Returns: u, v - the optical flow\n",
    "    '''\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    # You can call OpticalFlowRefine iteratively\n",
    "\n",
    "    \n",
    "    return u, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numLevels=5\n",
    "window = 17\n",
    "U, V = LucasKanadeMultiScale(grayscale(images[0]),grayscale(images[1]),\\\n",
    "                          window,numLevels)\n",
    "# # Plot\n",
    "plot_optical_flow(images[0],U,V, \\\n",
    "                  'levels = ' + str(numLevels) + ', window = '+str(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e44a95",
   "metadata": {},
   "source": [
    "#### Problem 4.2.2: Number of levels\n",
    "\n",
    "Plot optical flow for the pair of images im1 and im2 for different number of levels mentioned below. Comment on the results and justify.<br>\n",
    "(i) window size = 13, numLevels = 1<br>\n",
    "(ii) window size = 13, numLevels = 3<br>\n",
    "(iii) window size = 13, numLevels = 5<br>\n",
    "So, you are expected to provide 3 outputs here<br>\n",
    "\n",
    "Note: if numLevels = 1, then it means the optical flow is only computed at the image resolution i.e. no downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to generate output\n",
    "numLevels=1\n",
    "U,V=LucasKanadeMultiScale(grayscale(images[0]),grayscale(images[1]),\\\n",
    "                          window,numLevels)\n",
    "plot_optical_flow(images[0],U,V, \\\n",
    "                  'levels = ' + str(numLevels) + ', window = '+str(window))\n",
    "\n",
    "numLevels=3\n",
    "U,V=LucasKanadeMultiScale(grayscale(images[0]),grayscale(images[1]),\\\n",
    "                          window,numLevels)\n",
    "# Plot\n",
    "plot_optical_flow(images[0],U,V, \\\n",
    "                  'levels = ' + str(numLevels) + ', window = '+str(window))\n",
    "\n",
    "numLevels=5\n",
    "U,V=LucasKanadeMultiScale(grayscale(images[0]),grayscale(images[1]),\\\n",
    "                          window,numLevels)\n",
    "# Plot\n",
    "plot_optical_flow(images[0],U,V, \\\n",
    "                  'levels = ' + str(numLevels) + ', window = '+str(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86016dc0",
   "metadata": {},
   "source": [
    "**Your comments here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664d28d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d98dc883",
   "metadata": {},
   "source": [
    "#### Problem 4.2.3: Window size\n",
    "\n",
    "Plot optical flow for the pair of images im1 and im2 for at least 3 different window sizes which leads to observable difference in the results. Comment on the effect of window size on results and justify. For this part fix the number of levels to be 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c33568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code, change as required\n",
    "numLevels=3\n",
    "\n",
    "w1, w2, w3 = 7, 11, 17\n",
    "for window in [w1, w2, w3]:\n",
    "    U,V=LucasKanadeMultiScale(grayscale(images[0]),grayscale(images[1]),\\\n",
    "                              window,numLevels)\n",
    "    plot_optical_flow(images[0],U,V, \\\n",
    "                      'levels = ' + str(numLevels) + ', window = '+str(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ade83be",
   "metadata": {},
   "source": [
    "**Your comments here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3608dce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80fedac5",
   "metadata": {},
   "source": [
    "#### Problem 4.2.4 All pairs\n",
    "\n",
    "Find optical ﬂow for the pairs (im1,im2), (im1,im3), (im1,im4) for a range of window sizes. Submit the best result for each pair. Does the optical ﬂow result seem consistent with visual inspection? Comment on the type of motion indicated by results and visual inspection and explain why they might be consistent or inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255be54f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use one fixed window and numLevels for all pairs\n",
    "numLevels = 5\n",
    "window = 17\n",
    "\n",
    "img0 = images[0]\n",
    "for i, image in enumerate(images):\n",
    "    if(i==0):\n",
    "        continue\n",
    "    img_new = images[i]\n",
    "    U,V = LucasKanadeMultiScale(grayscale(img0),grayscale(img_new),\\\n",
    "                              window,numLevels)\n",
    "    print(\"Image 1, Image \",(i+1))\n",
    "    # Plot\n",
    "    plot_optical_flow(img0,U,V, \\\n",
    "                      'levels = ' + str(numLevels) + ', window = '+str(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130fd30",
   "metadata": {},
   "source": [
    "**Your comments here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e5a4a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
